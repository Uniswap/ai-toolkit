---
description: Optimize prompts for better AI performance. Use when user says "improve this prompt for better results", "optimize this prompt to reduce tokens", "apply prompt engineering best practices to this", "make this prompt more effective", "help me refine this system prompt", or "tune this prompt for the AI model I'm using".
allowed-tools: Read, Write, WebSearch, WebFetch, Task(subagent_type:prompt-engineer-agent)
model: opus
---

# Prompt Optimizer

Optimize prompts for better AI model performance using engineering techniques.

## When to Activate

- User wants to improve a prompt
- Token efficiency needed
- Better AI responses desired
- Prompt engineering techniques requested
- Model-specific optimization needed

## Optimization Areas

### 1. Prompt Engineering

- Chain-of-thought reasoning
- Few-shot examples
- Role-based instructions
- Clear delimiters and formatting
- Output format specifications

### 2. Context Optimization

- Minimize token usage
- Hierarchical information structure
- Remove redundancy
- Add relevant context
- Compression techniques

### 3. Performance Testing

- Create prompt variants
- Design evaluation criteria
- Test edge cases
- Measure consistency
- Compare outputs

### 4. Model-Specific Optimization

- GPT-4 best practices
- Claude optimization techniques
- Prompt chaining strategies
- Temperature/parameter tuning
- Token budget management

### 5. RAG Integration

- Context window management
- Retrieval query optimization
- Chunk size recommendations
- Embedding strategies
- Reranking approaches

### 6. Production Considerations

- Prompt versioning
- A/B testing framework
- Monitoring metrics
- Fallback strategies
- Cost optimization

## Output

Provides:

- Optimized prompt variants
- Explanations for each change
- Evaluation metrics
- Testing strategies
- Quality and cost considerations
