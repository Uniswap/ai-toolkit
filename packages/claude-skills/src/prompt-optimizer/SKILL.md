---
name: prompt-optimizer
description: Optimize AI prompts for better model performance using prompt engineering techniques. Use when user wants to improve a prompt, optimize for better AI responses, reduce token usage, or apply prompt engineering best practices. Triggers: "optimize prompt", "improve prompt", "better prompt", "prompt engineering", "token efficiency", "prompt tuning", "refine prompt", "prompt performance".
allowed-tools: Read, Write, WebSearch, WebFetch, Task(subagent_type:prompt-engineer)
model: opus
---

# Prompt Optimizer

Optimize prompts for better AI model performance using engineering techniques.

## When to Activate

- User wants to improve a prompt
- Token efficiency needed
- Better AI responses desired
- Prompt engineering techniques requested
- Model-specific optimization needed

## Optimization Areas

### 1. Prompt Engineering

- Chain-of-thought reasoning
- Few-shot examples
- Role-based instructions
- Clear delimiters and formatting
- Output format specifications

### 2. Context Optimization

- Minimize token usage
- Hierarchical information structure
- Remove redundancy
- Add relevant context
- Compression techniques

### 3. Performance Testing

- Create prompt variants
- Design evaluation criteria
- Test edge cases
- Measure consistency
- Compare outputs

### 4. Model-Specific Optimization

- GPT-4 best practices
- Claude optimization techniques
- Prompt chaining strategies
- Temperature/parameter tuning
- Token budget management

### 5. RAG Integration

- Context window management
- Retrieval query optimization
- Chunk size recommendations
- Embedding strategies
- Reranking approaches

### 6. Production Considerations

- Prompt versioning
- A/B testing framework
- Monitoring metrics
- Fallback strategies
- Cost optimization

## Output

Provides:

- Optimized prompt variants
- Explanations for each change
- Evaluation metrics
- Testing strategies
- Quality and cost considerations
